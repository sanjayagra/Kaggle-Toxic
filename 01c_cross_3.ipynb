{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.layers import Dense, Dropout, GRU, Embedding, TimeDistributed, Flatten\n",
    "from keras.layers import Input, Activation, concatenate, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import RepeatVector, Permute, merge, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import np_utils, get_custom_objects\n",
    "from keras.preprocessing import text, sequence\n",
    "from string import ascii_letters, punctuation, digits\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "\n",
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "SEQ_LENGTH = 100\n",
    "EMBED_SIZE = 100\n",
    "VOCAB = 238590\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(matrix):\n",
    "    rnn = {}\n",
    "    rnn['units'] = 50\n",
    "    rnn['return_sequences'] = True\n",
    "    rnn['recurrent_dropout'] = 0.2\n",
    "    rnn['dropout'] = 0.1\n",
    "    rnn['activation'] = 'tanh'\n",
    "    inputs = Input(shape=(SEQ_LENGTH,), name='sequence')\n",
    "    embed = Embedding(VOCAB,EMBED_SIZE, weights=[matrix], trainable=False)(inputs)\n",
    "    lstm = GRU(**rnn)(embed)\n",
    "    atten = TimeDistributed(Dense(1, activation='tanh'))(lstm)\n",
    "    atten = Flatten()(atten)\n",
    "    atten = Activation('softmax')(atten)\n",
    "    atten = RepeatVector(rnn['units'])(atten)\n",
    "    atten = Permute([2, 1])(atten)\n",
    "    dense = merge([lstm, atten], mode='mul')\n",
    "    dense = Lambda(lambda xin: K.sum(xin, axis=1))(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(200, activation='swish')(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    predict = Dense(6, activation='sigmoid')(dense)\n",
    "    model = Model(inputs=[inputs], output=predict)\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93651 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('../data/data/fasttext/vector.vec')\n",
    "\n",
    "for line in f:\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        print(values[0])\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataflow(train_text, valid_text, score_text):\n",
    "    train_text['comment_text'] = train_text['comment_text'].fillna('nan')\n",
    "    valid_text['comment_text'] = valid_text['comment_text'].fillna('nan')\n",
    "    score_text['comment_text'] = score_text['comment_text'].fillna('nan')\n",
    "    train_text = list(train_text['comment_text'].values)\n",
    "    valid_text = list(valid_text['comment_text'].values)\n",
    "    score_text = list(score_text['comment_text'].values)\n",
    "    tokenizer = text.Tokenizer(lower=True, char_level=False, num_words=100000)\n",
    "    tokenizer.fit_on_texts(train_text + valid_text)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('total words:', len(word_index))\n",
    "    intersect = 0\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            intersect += 1\n",
    "    print('common words:', intersect)\n",
    "    score_token = tokenizer.texts_to_sequences(score_text)\n",
    "    score_seq = sequence.pad_sequences(score_token, maxlen=SEQ_LENGTH)\n",
    "    return score_seq, embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(mode):\n",
    "    train_text = pd.read_csv('../data/data/source_1/train/train_data_{}.csv'.format(mode))\n",
    "    valid_text = pd.read_csv('../data/data/source_1/train/test_data_{}.csv'.format(mode))\n",
    "    score_text = pd.read_csv('../data/data/source_1/train/test_data_{}.csv'.format(mode))\n",
    "    labels = pd.read_csv('../data/data/source_1/train/test_labels_{}.csv'.format(mode))\n",
    "    score_data = score_text[['id']]\n",
    "    score_text, embedding_matrix = dataflow(train_text, valid_text, score_text)\n",
    "    model = define_model(embedding_matrix)\n",
    "    path = '../data/data/source_1/model_3/model_{}.hdf5'.format(mode)\n",
    "    model.load_weights(path)\n",
    "    scores = model.predict(score_text, batch_size=512)\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "    scores = score_data.join(scores)\n",
    "    return scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 88118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:16: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 88118\n",
      "total words: 238589\n",
      "common words: 88118\n",
      "total words: 238589\n",
      "common words: 88118\n",
      "total words: 238589\n",
      "common words: 88118\n"
     ]
    }
   ],
   "source": [
    "score_1, labels_1 = score_model(1)\n",
    "score_2, labels_2 = score_model(2)\n",
    "score_3, labels_3 = score_model(3)\n",
    "score_4, labels_4 = score_model(4)\n",
    "score_5, labels_5 = score_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>7.191598e-08</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.805343e-07</td>\n",
       "      <td>3.187131e-06</td>\n",
       "      <td>1.722753e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>1.325167e-05</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>2.220314e-05</td>\n",
       "      <td>2.932923e-04</td>\n",
       "      <td>4.405921e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>1.138331e-05</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>5.583086e-05</td>\n",
       "      <td>6.639684e-04</td>\n",
       "      <td>1.669362e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19159</th>\n",
       "      <td>00013fa6fb6ef643</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>5.115979e-07</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>4.896253e-07</td>\n",
       "      <td>1.939144e-05</td>\n",
       "      <td>2.502788e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.417060e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>9.555013e-09</td>\n",
       "      <td>4.745190e-07</td>\n",
       "      <td>2.599188e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id     toxic  severe_toxic   obscene        threat  \\\n",
       "0      0000997932d777bf  0.000128  7.191598e-08  0.000009  1.805343e-07   \n",
       "0      000103f0d9cfb60f  0.002646  1.325167e-05  0.000602  2.220314e-05   \n",
       "0      000113f07ec002fd  0.013740  1.138331e-05  0.001181  5.583086e-05   \n",
       "19159  00013fa6fb6ef643  0.001132  5.115979e-07  0.000214  4.896253e-07   \n",
       "0      0001b41b1c6bb37e  0.000011  1.417060e-06  0.000018  9.555013e-09   \n",
       "\n",
       "             insult  identity_hate  \n",
       "0      3.187131e-06   1.722753e-07  \n",
       "0      2.932923e-04   4.405921e-05  \n",
       "0      6.639684e-04   1.669362e-05  \n",
       "19159  1.939144e-05   2.502788e-06  \n",
       "0      4.745190e-07   2.599188e-07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = score_1.append(score_2)\n",
    "submit = submit.append(score_3)\n",
    "submit = submit.append(score_4)\n",
    "submit = submit.append(score_5)\n",
    "submit = submit.sort_values(by='id')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19159</th>\n",
       "      <td>00013fa6fb6ef643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0      0000997932d777bf      0             0        0       0       0   \n",
       "0      000103f0d9cfb60f      0             0        0       0       0   \n",
       "0      000113f07ec002fd      0             0        0       0       0   \n",
       "19159  00013fa6fb6ef643      0             0        0       0       0   \n",
       "0      0001b41b1c6bb37e      0             0        0       0       0   \n",
       "\n",
       "       identity_hate  \n",
       "0                  0  \n",
       "0                  0  \n",
       "0                  0  \n",
       "19159              0  \n",
       "0                  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_1.append(labels_2)\n",
    "labels = labels.append(labels_3)\n",
    "labels = labels.append(labels_4)\n",
    "labels = labels.append(labels_5)\n",
    "labels = labels.sort_values(by='id')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset: toxic : 0.9596\n",
      "subset: severe_toxic : 0.9784\n",
      "subset: obscene : 0.98\n",
      "subset: threat : 0.9729\n",
      "subset: insult : 0.9707\n",
      "subset: identity_hate : 0.9673\n",
      "overall: 0.9715\n"
     ]
    }
   ],
   "source": [
    "models = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "evaluate = 0.\n",
    "\n",
    "for subset in models:\n",
    "    predict = submit[subset]\n",
    "    actual = labels[subset]\n",
    "    fpr, tpr, threshold = roc_curve(actual, predict)\n",
    "    metric = round(2*auc(fpr, tpr)-1, 4)\n",
    "    print('subset:', subset, ':', metric)\n",
    "    evaluate += metric\n",
    "    \n",
    "print('overall:', round(evaluate/6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../data/model/baseline_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
