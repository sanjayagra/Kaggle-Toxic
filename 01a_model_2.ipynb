{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.layers import Dense, Dropout, GRU, Embedding \n",
    "from keras.layers import Input, Activation, concatenate, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import np_utils, get_custom_objects\n",
    "from keras.preprocessing import text, sequence\n",
    "from string import ascii_letters, punctuation, digits\n",
    "\n",
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "SEQ_LENGTH = 100\n",
    "EMBED_SIZE = 300\n",
    "VOCAB = 238590\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(matrix, status, learn):\n",
    "    rnn = {}\n",
    "    rnn['units'] = 75\n",
    "    rnn['return_sequences'] = True\n",
    "    rnn['recurrent_dropout'] = 0.2\n",
    "    rnn['dropout'] = 0.1\n",
    "    rnn['activation'] = 'tanh'\n",
    "    inputs = Input(shape=(SEQ_LENGTH,), name='sequence')\n",
    "    embed = Embedding(VOCAB,EMBED_SIZE, weights=[matrix], trainable=status)(inputs)\n",
    "    lstm = Bidirectional(GRU(**rnn))(embed)\n",
    "    lstm = BatchNormalization()(lstm)\n",
    "    max_pool = GlobalMaxPooling1D()(lstm)\n",
    "    avg_pool = GlobalAveragePooling1D()(lstm)\n",
    "    pool = concatenate([max_pool, avg_pool])\n",
    "    pool = BatchNormalization()(pool)\n",
    "    lstm = Dropout(0.2)(pool)\n",
    "    dense = Dense(200, activation='swish')(lstm)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    predict = Dense(6, activation='sigmoid')(dense)\n",
    "    model = Model(inputs=[inputs], output=predict)\n",
    "    optimizer = Adam(lr=learn)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('../data/download/glove.6B.300d.txt')\n",
    "\n",
    "for line in f:\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        print(values[0])\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataflow(train_text, valid_text):\n",
    "    train_text['comment_text'] = train_text['comment_text'].fillna('nan')\n",
    "    valid_text['comment_text'] = valid_text['comment_text'].fillna('nan')\n",
    "    train_text = list(train_text['comment_text'].values)\n",
    "    valid_text = list(valid_text['comment_text'].values)\n",
    "    tokenizer = text.Tokenizer(lower=True, char_level=False, num_words=20000)\n",
    "    tokenizer.fit_on_texts(train_text + valid_text)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('total words:', len(word_index))\n",
    "    intersect = 0\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            intersect += 1\n",
    "    print('common words:', intersect)\n",
    "    train_token = tokenizer.texts_to_sequences(train_text)\n",
    "    valid_token = tokenizer.texts_to_sequences(valid_text)\n",
    "    train_seq = sequence.pad_sequences(train_token, maxlen=SEQ_LENGTH)\n",
    "    valid_seq = sequence.pad_sequences(valid_token, maxlen=SEQ_LENGTH)\n",
    "    return train_seq, valid_seq, embedding_matrix\n",
    "\n",
    "def callbacks(suffix):\n",
    "    stop = EarlyStopping('val_loss', patience=3, mode=\"min\")\n",
    "    path = '../data/data/source_1/model_2/model_{}.hdf5'.format(suffix)\n",
    "    save = ModelCheckpoint(path, save_best_only=True, save_weights_only=True)\n",
    "    logger = CSVLogger('../data/data/source_1/model_2/logger_{}.log'.format(suffix))\n",
    "    reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=2, verbose=0, mode='min')\n",
    "    return [stop, save, reduce, logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data : fold - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 94353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/15\n",
      "127656/127656 [==============================] - 355s 3ms/step - loss: 0.0750 - acc: 0.9749 - val_loss: 0.0517 - val_acc: 0.9816\n",
      "Epoch 2/15\n",
      "127656/127656 [==============================] - 356s 3ms/step - loss: 0.0535 - acc: 0.9810 - val_loss: 0.0472 - val_acc: 0.9825\n",
      "Epoch 3/15\n",
      "127656/127656 [==============================] - 346s 3ms/step - loss: 0.0496 - acc: 0.9821 - val_loss: 0.0458 - val_acc: 0.9829\n",
      "Epoch 4/15\n",
      "127656/127656 [==============================] - 229s 2ms/step - loss: 0.0469 - acc: 0.9827 - val_loss: 0.0459 - val_acc: 0.9830\n",
      "Epoch 5/15\n",
      "127656/127656 [==============================] - 358s 3ms/step - loss: 0.0450 - acc: 0.9832 - val_loss: 0.0455 - val_acc: 0.9832\n",
      "Epoch 6/15\n",
      "127656/127656 [==============================] - 354s 3ms/step - loss: 0.0437 - acc: 0.9836 - val_loss: 0.0445 - val_acc: 0.9836\n",
      "Epoch 7/15\n",
      "127656/127656 [==============================] - 325s 3ms/step - loss: 0.0422 - acc: 0.9840 - val_loss: 0.0457 - val_acc: 0.9827\n",
      "Epoch 8/15\n",
      "127656/127656 [==============================] - 334s 3ms/step - loss: 0.0408 - acc: 0.9845 - val_loss: 0.0474 - val_acc: 0.9836\n",
      "Epoch 9/15\n",
      "127656/127656 [==============================] - 323s 3ms/step - loss: 0.0396 - acc: 0.9848 - val_loss: 0.0452 - val_acc: 0.9834\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/3\n",
      "127656/127656 [==============================] - 646s 5ms/step - loss: 0.0401 - acc: 0.9847 - val_loss: 0.0437 - val_acc: 0.9835\n",
      "Epoch 2/3\n",
      "127656/127656 [==============================] - 624s 5ms/step - loss: 0.0386 - acc: 0.9850 - val_loss: 0.0440 - val_acc: 0.9833\n",
      "Epoch 3/3\n",
      "127656/127656 [==============================] - 625s 5ms/step - loss: 0.0377 - acc: 0.9854 - val_loss: 0.0440 - val_acc: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f006f6e2828>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = pd.read_csv('../data/data/source_1/train/train_data_1.csv')\n",
    "train_label = pd.read_csv('../data/data/source_1/train/train_labels_1.csv')\n",
    "valid_text = pd.read_csv('../data/data/source_1/train/test_data_1.csv')\n",
    "valid_label = pd.read_csv('../data/data/source_1/train/test_labels_1.csv')\n",
    "train_text, valid_text, embedding_matrix = dataflow(train_text, valid_text)\n",
    "\n",
    "params = {}\n",
    "params['x'] = train_text\n",
    "params['y'] = np.array(train_label.iloc[:,1:])\n",
    "params['validation_data'] = (valid_text, np.array(valid_label.iloc[:,1:]))\n",
    "params['batch_size'] = 256\n",
    "params['epochs'] = 15\n",
    "params['verbose'] = 1\n",
    "params['callbacks'] = callbacks(1)\n",
    "# round-1\n",
    "model = define_model(embedding_matrix, False, 1e-3)\n",
    "model.fit(**params)\n",
    "# round-2\n",
    "params['epochs'] = 3\n",
    "model = define_model(embedding_matrix, True, 1e-4)\n",
    "path = '../data/data/source_1/model_2/model_{}.hdf5'.format(1)\n",
    "model.load_weights(path)\n",
    "model.fit(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data : fold - 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 94353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/15\n",
      "127657/127657 [==============================] - 336s 3ms/step - loss: 0.0815 - acc: 0.9715 - val_loss: 0.0521 - val_acc: 0.9813\n",
      "Epoch 2/15\n",
      "127657/127657 [==============================] - 331s 3ms/step - loss: 0.0539 - acc: 0.9809 - val_loss: 0.0494 - val_acc: 0.9820\n",
      "Epoch 3/15\n",
      "127657/127657 [==============================] - 333s 3ms/step - loss: 0.0494 - acc: 0.9820 - val_loss: 0.0500 - val_acc: 0.9815\n",
      "Epoch 4/15\n",
      "127657/127657 [==============================] - 341s 3ms/step - loss: 0.0470 - acc: 0.9826 - val_loss: 0.0473 - val_acc: 0.9822\n",
      "Epoch 5/15\n",
      "127657/127657 [==============================] - 328s 3ms/step - loss: 0.0454 - acc: 0.9830 - val_loss: 0.0481 - val_acc: 0.9827\n",
      "Epoch 6/15\n",
      "127657/127657 [==============================] - 347s 3ms/step - loss: 0.0433 - acc: 0.9837 - val_loss: 0.0463 - val_acc: 0.9831\n",
      "Epoch 7/15\n",
      "127657/127657 [==============================] - 328s 3ms/step - loss: 0.0420 - acc: 0.9840 - val_loss: 0.0466 - val_acc: 0.9828\n",
      "Epoch 8/15\n",
      "127657/127657 [==============================] - 329s 3ms/step - loss: 0.0407 - acc: 0.9844 - val_loss: 0.0465 - val_acc: 0.9829\n",
      "Epoch 9/15\n",
      "127657/127657 [==============================] - 333s 3ms/step - loss: 0.0397 - acc: 0.9848 - val_loss: 0.0477 - val_acc: 0.9827\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/3\n",
      "127657/127657 [==============================] - 643s 5ms/step - loss: 0.0398 - acc: 0.9847 - val_loss: 0.0459 - val_acc: 0.9830\n",
      "Epoch 2/3\n",
      "127657/127657 [==============================] - 644s 5ms/step - loss: 0.0386 - acc: 0.9851 - val_loss: 0.0458 - val_acc: 0.9832\n",
      "Epoch 3/3\n",
      "127657/127657 [==============================] - 619s 5ms/step - loss: 0.0375 - acc: 0.9854 - val_loss: 0.0461 - val_acc: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f003ebe2f60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = pd.read_csv('../data/data/source_1/train/train_data_2.csv')\n",
    "train_label = pd.read_csv('../data/data/source_1/train/train_labels_2.csv')\n",
    "valid_text = pd.read_csv('../data/data/source_1/train/test_data_2.csv')\n",
    "valid_label = pd.read_csv('../data/data/source_1/train/test_labels_2.csv')\n",
    "train_text, valid_text, embedding_matrix = dataflow(train_text, valid_text)\n",
    "\n",
    "params = {}\n",
    "params['x'] = train_text\n",
    "params['y'] = np.array(train_label.iloc[:,1:])\n",
    "params['validation_data'] = (valid_text, np.array(valid_label.iloc[:,1:]))\n",
    "params['batch_size'] = 256\n",
    "params['epochs'] = 15\n",
    "params['verbose'] = 1\n",
    "params['callbacks'] = callbacks(2)\n",
    "# round-1\n",
    "model = define_model(embedding_matrix, False, 1e-3)\n",
    "model.fit(**params)\n",
    "# round-2\n",
    "params['epochs'] = 3\n",
    "model = define_model(embedding_matrix, True, 1e-4)\n",
    "path = '../data/data/source_1/model_2/model_{}.hdf5'.format(2)\n",
    "model.load_weights(path)\n",
    "model.fit(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data : fold - 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 94353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00042c45f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = pd.read_csv('../data/data/source_1/train/train_data_3.csv')\n",
    "train_label = pd.read_csv('../data/data/source_1/train/train_labels_3.csv')\n",
    "valid_text = pd.read_csv('../data/data/source_1/train/test_data_3.csv')\n",
    "valid_label = pd.read_csv('../data/data/source_1/train/test_labels_3.csv')\n",
    "train_text, valid_text, embedding_matrix = dataflow(train_text, valid_text)\n",
    "\n",
    "params = {}\n",
    "params['x'] = train_text\n",
    "params['y'] = np.array(train_label.iloc[:,1:])\n",
    "params['validation_data'] = (valid_text, np.array(valid_label.iloc[:,1:]))\n",
    "params['batch_size'] = 256\n",
    "params['epochs'] = 15\n",
    "params['verbose'] = 0\n",
    "params['callbacks'] = callbacks(3)\n",
    "# round-1\n",
    "model = define_model(embedding_matrix, False, 1e-3)\n",
    "model.fit(**params)\n",
    "# round-2\n",
    "params['epochs'] = 3\n",
    "model = define_model(embedding_matrix, True, 1e-4)\n",
    "path = '../data/data/source_1/model_2/model_{}.hdf5'.format(3)\n",
    "model.load_weights(path)\n",
    "model.fit(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data : fold - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 94353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efff6a9be48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = pd.read_csv('../data/data/source_1/train/train_data_4.csv')\n",
    "train_label = pd.read_csv('../data/data/source_1/train/train_labels_4.csv')\n",
    "valid_text = pd.read_csv('../data/data/source_1/train/test_data_4.csv')\n",
    "valid_label = pd.read_csv('../data/data/source_1/train/test_labels_4.csv')\n",
    "train_text, valid_text, embedding_matrix = dataflow(train_text, valid_text)\n",
    "\n",
    "params = {}\n",
    "params['x'] = train_text\n",
    "params['y'] = np.array(train_label.iloc[:,1:])\n",
    "params['validation_data'] = (valid_text, np.array(valid_label.iloc[:,1:]))\n",
    "params['batch_size'] = 256\n",
    "params['epochs'] = 15\n",
    "params['verbose'] = 0\n",
    "params['callbacks'] = callbacks(4)\n",
    "# round-1\n",
    "model = define_model(embedding_matrix, False, 1e-3)\n",
    "model.fit(**params)\n",
    "# round-2\n",
    "params['epochs'] = 3\n",
    "model = define_model(embedding_matrix, True, 1e-4)\n",
    "path = '../data/data/source_1/model_2/model_{}.hdf5'.format(4)\n",
    "model.load_weights(path)\n",
    "model.fit(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data : fold - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 94353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7effee804438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = pd.read_csv('../data/data/source_1/train/train_data_5.csv')\n",
    "train_label = pd.read_csv('../data/data/source_1/train/train_labels_5.csv')\n",
    "valid_text = pd.read_csv('../data/data/source_1/train/test_data_5.csv')\n",
    "valid_label = pd.read_csv('../data/data/source_1/train/test_labels_5.csv')\n",
    "train_text, valid_text, embedding_matrix = dataflow(train_text, valid_text)\n",
    "\n",
    "params = {}\n",
    "params['x'] = train_text\n",
    "params['y'] = np.array(train_label.iloc[:,1:])\n",
    "params['validation_data'] = (valid_text, np.array(valid_label.iloc[:,1:]))\n",
    "params['batch_size'] = 256\n",
    "params['epochs'] = 15\n",
    "params['verbose'] = 0\n",
    "params['callbacks'] = callbacks(5)\n",
    "# round-1\n",
    "model = define_model(embedding_matrix, False, 1e-3)\n",
    "model.fit(**params)\n",
    "# round-2\n",
    "params['epochs'] = 3\n",
    "model = define_model(embedding_matrix, True, 1e-4)\n",
    "path = '../data/data/source_1/model_2/model_{}.hdf5'.format(5)\n",
    "model.load_weights(path)\n",
    "model.fit(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
