{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.layers import Dense, Dropout, GRU, Embedding \n",
    "from keras.layers import Input, Activation, concatenate, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import np_utils, get_custom_objects\n",
    "from keras.preprocessing import text, sequence\n",
    "from string import ascii_letters, punctuation, digits\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "\n",
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "SEQ_LENGTH = 100\n",
    "EMBED_SIZE = 100\n",
    "VOCAB = 238590\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(matrix):\n",
    "    rnn = {}\n",
    "    rnn['units'] = 50\n",
    "    rnn['return_sequences'] = True\n",
    "    rnn['recurrent_dropout'] = 0.2\n",
    "    rnn['dropout'] = 0.1\n",
    "    rnn['activation'] = 'tanh'\n",
    "    inputs = Input(shape=(SEQ_LENGTH,), name='sequence')\n",
    "    embed = Embedding(VOCAB,EMBED_SIZE, weights=[matrix], trainable=False)(inputs)\n",
    "    lstm = Bidirectional(GRU(**rnn))(embed)\n",
    "    lstm = BatchNormalization()(lstm)\n",
    "    max_pool = GlobalMaxPooling1D()(lstm)\n",
    "    avg_pool = GlobalAveragePooling1D()(lstm)\n",
    "    pool = concatenate([max_pool, avg_pool])\n",
    "    pool = BatchNormalization()(pool)\n",
    "    lstm = Dropout(0.2)(pool)\n",
    "    dense = Dense(200, activation='swish')(lstm)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    predict = Dense(6, activation='sigmoid')(dense)\n",
    "    model = Model(inputs=[inputs], output=predict)\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93651 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open('../data/data/fasttext/vector.vec')\n",
    "\n",
    "for line in f:\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        print(values[0])\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataflow(train_text, valid_text, score_text):\n",
    "    train_text['comment_text'] = train_text['comment_text'].fillna('nan')\n",
    "    valid_text['comment_text'] = valid_text['comment_text'].fillna('nan')\n",
    "    score_text['comment_text'] = score_text['comment_text'].fillna('nan')\n",
    "    train_text = list(train_text['comment_text'].values)\n",
    "    valid_text = list(valid_text['comment_text'].values)\n",
    "    score_text = list(score_text['comment_text'].values)\n",
    "    tokenizer = text.Tokenizer(lower=True, char_level=False, num_words=100000)\n",
    "    tokenizer.fit_on_texts(train_text + valid_text)\n",
    "    word_index = tokenizer.word_index\n",
    "    print('total words:', len(word_index))\n",
    "    intersect = 0\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            intersect += 1\n",
    "    print('common words:', intersect)\n",
    "    score_token = tokenizer.texts_to_sequences(score_text)\n",
    "    score_seq = sequence.pad_sequences(score_token, maxlen=SEQ_LENGTH)\n",
    "    return score_seq, embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(mode):\n",
    "    train_text = pd.read_csv('../data/data/source_1/train/train_data_{}.csv'.format(mode))\n",
    "    valid_text = pd.read_csv('../data/data/source_1/train/test_data_{}.csv'.format(mode))\n",
    "    score_text = pd.read_csv('../data/data/source_1/train/test_data_{}.csv'.format(mode))\n",
    "    labels = pd.read_csv('../data/data/source_1/train/test_labels_{}.csv'.format(mode))\n",
    "    score_data = score_text[['id']]\n",
    "    score_text, embedding_matrix = dataflow(train_text, valid_text, score_text)\n",
    "    model = define_model(embedding_matrix)\n",
    "    path = '../data/data/source_1/model_1/model_{}.hdf5'.format(mode)\n",
    "    model.load_weights(path)\n",
    "    scores = model.predict(score_text, batch_size=512)\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "    scores = score_data.join(scores)\n",
    "    return scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 88118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 238589\n",
      "common words: 88118\n",
      "total words: 238589\n",
      "common words: 88118\n",
      "total words: 238589\n",
      "common words: 88118\n",
      "total words: 238589\n",
      "common words: 88118\n"
     ]
    }
   ],
   "source": [
    "score_1, labels_1 = score_model(1)\n",
    "score_2, labels_2 = score_model(2)\n",
    "score_3, labels_3 = score_model(3)\n",
    "score_4, labels_4 = score_model(4)\n",
    "score_5, labels_5 = score_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>2.231336e-08</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>5.852413e-07</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>4.729260e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>2.662309e-07</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>8.351806e-07</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>5.079758e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>2.803684e-07</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>5.480756e-07</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>2.174666e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19159</th>\n",
       "      <td>00013fa6fb6ef643</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>5.248990e-06</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>2.768307e-06</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>4.767489e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>6.888590e-08</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>3.860377e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.234249e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id     toxic  severe_toxic   obscene        threat  \\\n",
       "0      0000997932d777bf  0.000852  2.231336e-08  0.000048  5.852413e-07   \n",
       "0      000103f0d9cfb60f  0.001208  2.662309e-07  0.000152  8.351806e-07   \n",
       "0      000113f07ec002fd  0.006603  2.803684e-07  0.000368  5.480756e-07   \n",
       "19159  00013fa6fb6ef643  0.001079  5.248990e-06  0.000541  2.768307e-06   \n",
       "0      0001b41b1c6bb37e  0.000006  6.888590e-08  0.000065  3.860377e-08   \n",
       "\n",
       "         insult  identity_hate  \n",
       "0      0.000023   4.729260e-07  \n",
       "0      0.000070   5.079758e-06  \n",
       "0      0.000310   2.174666e-06  \n",
       "19159  0.000080   4.767489e-06  \n",
       "0      0.000002   1.234249e-06  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = score_1.append(score_2)\n",
    "submit = submit.append(score_3)\n",
    "submit = submit.append(score_4)\n",
    "submit = submit.append(score_5)\n",
    "submit = submit.sort_values(by='id')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19159</th>\n",
       "      <td>00013fa6fb6ef643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0      0000997932d777bf      0             0        0       0       0   \n",
       "0      000103f0d9cfb60f      0             0        0       0       0   \n",
       "0      000113f07ec002fd      0             0        0       0       0   \n",
       "19159  00013fa6fb6ef643      0             0        0       0       0   \n",
       "0      0001b41b1c6bb37e      0             0        0       0       0   \n",
       "\n",
       "       identity_hate  \n",
       "0                  0  \n",
       "0                  0  \n",
       "0                  0  \n",
       "19159              0  \n",
       "0                  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_1.append(labels_2)\n",
    "labels = labels.append(labels_3)\n",
    "labels = labels.append(labels_4)\n",
    "labels = labels.append(labels_5)\n",
    "labels = labels.sort_values(by='id')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset: toxic : 0.9609\n",
      "subset: severe_toxic : 0.9794\n",
      "subset: obscene : 0.9805\n",
      "subset: threat : 0.98\n",
      "subset: insult : 0.9717\n",
      "subset: identity_hate : 0.968\n",
      "overall: 0.9734\n"
     ]
    }
   ],
   "source": [
    "models = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "evaluate = 0.\n",
    "\n",
    "for subset in models:\n",
    "    predict = submit[subset]\n",
    "    actual = labels[subset]\n",
    "    fpr, tpr, threshold = roc_curve(actual, predict)\n",
    "    metric = round(2*auc(fpr, tpr)-1, 4)\n",
    "    print('subset:', subset, ':', metric)\n",
    "    evaluate += metric\n",
    "    \n",
    "print('overall:', round(evaluate/6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../data/model/baseline_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
